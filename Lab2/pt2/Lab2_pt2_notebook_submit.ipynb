{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "import zipfile\n",
    "import os\n",
    "\n",
    "# Function to download and extract a dataset\n",
    "def download_and_extract(url, target_path, extract_path):\n",
    "    response = requests.get(url)\n",
    "    if response.status_code == 200:\n",
    "        with open(target_path, 'wb') as file:\n",
    "            file.write(response.content)\n",
    "        with zipfile.ZipFile(target_path, 'r') as zip_ref:\n",
    "            zip_ref.extractall(extract_path)\n",
    "\n",
    "# URLs for the datasets\n",
    "NLCD_url = 'https://resources.gisdata.mn.gov/pub/gdrs/data/pub/us_mn_state_dnr/biota_landcover_nlcd_mn_2019/tif_biota_landcover_nlcd_mn_2019.zip'\n",
    "DEM_url = 'https://resources.gisdata.mn.gov/pub/gdrs/data/pub/us_mn_state_dnr/elev_30m_digital_elevation_model/fgdb_elev_30m_digital_elevation_model.zip'\n",
    "county_url = 'https://resources.gisdata.mn.gov/pub/gdrs/data/pub/us_mn_state_dnr/bdry_counties_in_minnesota/shp_bdry_counties_in_minnesota.zip'\n",
    "\n",
    "# Directory where you want to save the datasets\n",
    "base_dir = r\"C:\\Users\\jake1\\OneDrive\\Documents\\ArcGIS\\Projects\\Lab2_pt2\"\n",
    "# Create new directories for unzipped data\n",
    "unzipped_NLCD_dir = os.path.join(base_dir, 'Unzipped Landcover')\n",
    "unzipped_DEM_dir = os.path.join(base_dir, 'Unzipped Elevation')\n",
    "unzipped_county_dir = os.path.join(base_dir, 'Unzipped Counties')\n",
    "\n",
    "# Download and extract the landcover dataset\n",
    "NLCD_path = os.path.join(base_dir, 'landcover.zip')\n",
    "download_and_extract(NLCD_url, NLCD_path, unzipped_NLCD_dir)\n",
    "\n",
    "# Download and extract the elevation dataset\n",
    "DEM_path = os.path.join(base_dir, 'elevation.zip')\n",
    "download_and_extract(DEM_url, DEM_path, unzipped_DEM_dir)\n",
    "\n",
    "# Download and extract the counties dataset\n",
    "county_path = os.path.join(base_dir, 'counties.zip')\n",
    "download_and_extract(county_url, county_path, unzipped_county_dir)\n",
    "\n",
    "print(\"All folders successfully downloaded and extracted\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import shutil\n",
    "\n",
    "# Define the new folder name\n",
    "merged_fh = 'geodatabase'\n",
    "\n",
    "# Create a directory for the merged data\n",
    "merged_folder = os.path.join(base_dir, merged_fh)\n",
    "os.makedirs(merged_folder, exist_ok=True)\n",
    "\n",
    "# List the subdirectories to merge\n",
    "subdirectories = ['Unzipped Landcover', 'Unzipped Elevation', 'Unzipped Counties']\n",
    "\n",
    "# Iterate through the subdirectories and copy their contents to the merged folder\n",
    "for subdirectory in subdirectories:\n",
    "    subdirectory_path = os.path.join(base_dir, subdirectory)\n",
    "    if os.path.exists(subdirectory_path):\n",
    "        for root, dirs, files in os.walk(subdirectory_path):\n",
    "            for file in files:\n",
    "                file_path = os.path.join(root, file)\n",
    "                shutil.copy(file_path, merged_folder)\n",
    "    print(\"Data from\", subdirectory, \"was merged\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### File Setup Complete!\n",
    "\n",
    "Now, our input data are conveniently merged into a single folder called 'merged_data'\n",
    "\n",
    "**Action Required:** Move the 'mn_county_boundaries' shape files from merged_data dir to the parent directory, Lab2_pt2."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "import arcpy\n",
    "# Set the workspace and input feature class\n",
    "arcpy.env.workspace = r\"C:\\Users\\jake1\\OneDrive\\Documents\\ArcGIS\\Projects\\Lab_Part2\"\n",
    "input_feature_class = \"mn_county_boundaries\"\n",
    "\n",
    "# Select county boundaries\n",
    "selected = arcpy.management.SelectLayerByAttribute(input_feature_class, \"NEW_SELECTION\", where_clause = \"CTY_Name IN ('Wabasha', 'Winona', 'Olmsted')\")\n",
    "\n",
    "# Create a feature layer with the selection\n",
    "arcpy.management.CopyFeatures(selected, \"Selected_Counties\")\n",
    "\n",
    "# Specify the output feature class for the selected features\n",
    "output_feature_class = r\"C:\\Users\\jake1\\OneDrive\\Documents\\ArcGIS\\Projects\\Lab_Part2\\mn_county_boundaries_Clip\"\n",
    "\n",
    "print(\"Successfully Clipped counties of interest.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ArcGIS Pro Map \n",
    "\n",
    "You should now see that two feature layers just appeared in your Contents Pane: 'Selected_Counties' and 'mn_county_boundaries_Layer2'.\n",
    "\n",
    "Remove 'mn_county_boundaries_Layer2' so you can see only the Hennepin County boundaries.\n",
    "\n",
    "Now that we have our boundaries for Hennepin County, we need to use the Extract by Mask function to extract our land cover data to *just* our clipped county polygons.\n",
    "\n",
    "**Action Required:** Move the \"NLCD_2019_Land_Cover.tif\" files to the parent directory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Confine land cover data to selected counties using extract by mask tool\n",
    "land_cover = arcpy.sa.ExtractByMask(\n",
    "    in_raster=\"NLCD_2019_Land_Cover.tif\",\n",
    "    in_mask_data=\"Selected_Counties\",\n",
    "    extraction_area=\"INSIDE\",\n",
    "    analysis_extent = \"NLCD_2019_Land_Cover.tif\"\n",
    ")\n",
    "print('Land Cover layer successfully extracted')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Map Update\n",
    "\n",
    "If correct, you should see the NLCD 2019 land cover data for Hennepin County in your contents pane as a raster layer named 'land_cover'. To see this on your map, unselect the 'Selected_Counties' layer.\n",
    "\n",
    "Now, we need to add our DEM to the map. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Set the directory of the DEM .gdb to the workspace\n",
    "arcpy.env.workspace = r'C:\\Users\\jake1\\OneDrive\\Documents\\ArcGIS\\Projects\\GIS_5571_Project\\Unzipped Elevation\\elev_30m_digital_elevation_model.gdb'\n",
    "# Name of DEM file: 'digital_elevation_model_30m'\n",
    "\n",
    "# Use extract by mask function to extract the DEM inside Hennepin County \n",
    "DEM = arcpy.sa.ExtractByMask(\n",
    "    in_raster = 'digital_elevation_model_30m',\n",
    "    in_mask_data = 'Selected_Counties',\n",
    "    extraction_area = 'INSIDE',\n",
    "    analysis_extent = 'digital_elevation_model_30m'\n",
    ")\n",
    "\n",
    "print('DEM successfully extracted')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Map Update\n",
    "\n",
    "If correct, you should see the DEM data for Hennepin County in your contents pane as a geodatabase raster named 'DEM'.\n",
    "\n",
    "Now, we need to adjust the slope of our DEM."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gdb_dir = (base_dir + '\\Lab2_pt2.gdb')\n",
    "\n",
    "arcpy.env.workspace = gdb_dir\n",
    "\n",
    "# Find slope from DEM\n",
    "Slope_Extrac1 = arcpy.sa.Slope(\n",
    "    in_raster=\"Extract_digi1\",\n",
    "    output_measurement=\"DEGREE\",\n",
    "    z_factor=1,\n",
    "    method=\"PLANAR\",\n",
    "    z_unit=\"METER\")\n",
    "\n",
    "print('Slope successfully adjusted')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create start and end points\n",
    "arcpy.management.CreateFeatureclass(\n",
    "    out_path = gdb_dir,\n",
    "    out_name = \"start_end_Locations\",\n",
    "    geometry_type = \"POINT\",\n",
    "    template = None,\n",
    "    has_m = \"DISABLED\",\n",
    "    has_z = \"DISABLED\",\n",
    "    spatial_reference='PROJCS[\"NAD_1983_UTM_Zone_15N\",GEOGCS[\"GCS_North_American_1983\",DATUM[\"D_North_American_1983\",SPHEROID[\"GRS_1980\",6378137.0,298.257222101]],PRIMEM[\"Greenwich\",0.0],UNIT[\"Degree\",0.0174532925199433]],PROJECTION[\"Transverse_Mercator\"],PARAMETER[\"False_Easting\",500000.0],PARAMETER[\"False_Northing\",0.0],PARAMETER[\"Central_Meridian\",-93.0],PARAMETER[\"Scale_Factor\",0.9996],PARAMETER[\"Latitude_Of_Origin\",0.0],UNIT[\"Meter\",1.0]];-5120900 -9998100 10000;-100000 10000;-100000 10000;0.001;0.001;0.001;IsHighPrecision',\n",
    "    config_keyword=\"\",\n",
    "    spatial_grid_1 = 0,\n",
    "    spatial_grid_2 = 0,\n",
    "    spatial_grid_3 = 0,\n",
    "    out_alias = \"\"\n",
    ")\n",
    "print(\"Dory's house and picnic area points successfully added\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Math to figure out my slope reclassification values\n",
    "def create_eql_classes(length, max_value):\n",
    "    if length <= 0:\n",
    "        return []  # Return an empty list if the length is non-positive\n",
    "\n",
    "    # Calculate the value to be assigned to each element\n",
    "    value = max_value / length\n",
    "\n",
    "    # Create the list using a list comprehension\n",
    "    result_list = [value * (i + 1) for i in range(length)]\n",
    "    \n",
    "    return result_list\n",
    "\n",
    "# Initialize parameters\n",
    "length = 5\n",
    "max_value = 79.383194\n",
    "# Call function\n",
    "my_list = create_eql_classes(length, max_value)\n",
    "\n",
    "# List output values\n",
    "for i in my_list:\n",
    "    print('value: {:.5f}'.format(i))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reclassify DEM slope\n",
    "slope_reclass = arcpy.sa.Reclassify(\n",
    "    in_raster=\"Slope_Extrac1\",\n",
    "    reclass_field=\"VALUE\",\n",
    "    remap=\"0 16 1;16 32 2;32 48 3;48 64 4;64 79.383194 5\",\n",
    "    missing_values=\"DATA\"\n",
    ")\n",
    "print('Slope reclassified')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reclassify NLCD data\n",
    "reclass_NLCD = arcpy.sa.Reclassify(\n",
    "    in_raster=\"land_cover\",\n",
    "    reclass_field=\"NLCD_Land\",\n",
    "    remap=\"'Open Water' 5;'Developed, Open Space' 1;'Developed, Low Intensity' 1;'Developed, Medium Intensity' 1;'Developed, High Intensity' 5;'Barren Land' 1;'Deciduous Forest' 1;'Evergreen Forest' 1;'Mixed Forest' 1;Shrub/Scrub 1;Herbaceous 1;Hay/Pasture 3;'Cultivated Crops' 5;'Woody Wetlands' 3;'Emergent Herbaceous Wetlands' 2\",\n",
    "    missing_values=\"DATA\"\n",
    ")\n",
    "print('Land Cover reclassified')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "# Create Several Cost Surfaces to Test Different Model Weights\n",
    "for i in np.arange(0.1, 1.0, 0.1):\n",
    "    # Set Weights\n",
    "    slope_weight = round(i, 1)\n",
    "    landcover_weight = round((1 - i), 1)\n",
    "    \n",
    "    # Calculate Cost and Save as New Raster\n",
    "    cost = ((((arcpy.Raster('Reclass_Slop2') * slope_weight) + (arcpy.Raster('Reclass_Extr1') * landcover_weight)) * -1) + 6)\n",
    "\n",
    "    output_name = f\"Slope_{slope_weight}_Landcover_{int(1 - landcover_weight)}\"\n",
    "    \n",
    "    # Save cost paths to .gdb with desecriptive name\n",
    "    cost.save(os.path.join(gdb_dir, output_name))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "# Create Several Cost Surfaces to Test Different Model Weights\n",
    "for i in np.arange(0.1, 1.0, 0.1):\n",
    "    # Set Weights\n",
    "    slope_weight = round(i, 1)\n",
    "    landcover_weight = round((1 - i), 1)\n",
    "    \n",
    "    arcpy.sa.OptimalRegionConnections(\"start_end_locations\", \n",
    "        fr\"cPath_{str(slope_weight)[2:3]}s_{str(landcover_weight)[2:3]}lc\", \n",
    "        in_cost_raster = ((((arcpy.Raster('slope_reclass') * slope_weight) + (arcpy.Raster('reclass_NLCD') * landcover_weight)) * -1) + 6)\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set the workspace and environment settings\n",
    "arcpy.env.workspace = gdb_dir\n",
    "arcpy.env.overwriteOutput = True\n",
    "\n",
    "# Define the input data (Land Cover and DEM)\n",
    "land_cover = \"reclass_NLCD\"\n",
    "dem = \"slope_reclass\"\n",
    "\n",
    "# Define the output folder for saving results\n",
    "output_folder = base_dir\n",
    "\n",
    "# Create a list of weight values to iterate through\n",
    "weight_values = [0.1, 0.2, 0.3, 0.4, 0.5, 0.6, 0.7, 0.8, 0.9]\n",
    "\n",
    "# Iterate through different weight values\n",
    "for weight in weight_values:\n",
    "    # Calculate suitability using weighted overlay\n",
    "    weighted_suitability = (arcpy.Raster(land_cover) * weight) + (arcpy.Raster(dem) * (1 - weight))\n",
    "\n",
    "    # Normalize the suitability scores if needed\n",
    "    # normalized_suitability = arcpy.Normalize(weighted_suitability)\n",
    "\n",
    "    # Save the suitability raster with a filename based on the weight\n",
    "    output_name = f\"Suitability_w{int(weight * 100)}.tif\"\n",
    "    output_path = os.path.join(output_folder, output_name)\n",
    "    weighted_suitability.save(output_path)\n",
    "\n",
    "    # Optionally, perform further analysis or reporting here\n",
    "\n",
    "print(\"Sensitivity analysis completed.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Optional routing function returned error... I'll just show suitability analysis\n",
    "\n",
    "# Analysis of Suitability \n",
    "\n",
    "# Set your workspace folder where output files are located\n",
    "arcpy.env.workspace = base_dir\n",
    "workspace = base_dir\n",
    "\n",
    "# List of output raster files\n",
    "output_files = [os.path.join(workspace, filename) for filename in os.listdir(workspace) if filename.endswith('.tif')]\n",
    "\n",
    "# Analyze each output file\n",
    "for file_path in output_files:\n",
    "    # Example analysis tasks (you can customize this)\n",
    "    \n",
    "    # Open the raster file\n",
    "    raster = arcpy.Raster(file_path)  # Use arcpy or other libraries for different GIS formats\n",
    "    \n",
    "    # Calculate statistics\n",
    "    mean = arcpy.GetRasterProperties_management(raster, \"MEAN\")\n",
    "    min_value = arcpy.GetRasterProperties_management(raster, \"MINIMUM\")\n",
    "    max_value = arcpy.GetRasterProperties_management(raster, \"MAXIMUM\")\n",
    "    \n",
    "    # Print or save the results\n",
    "    print(f\"Analysis for {file_path}:\")\n",
    "    print(f\"Mean: {mean}\")\n",
    "    print(f\"Minimum: {min_value}\")\n",
    "    print(f\"Maximum: {max_value}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "\n",
    "# List of output raster files\n",
    "output_files = [os.path.join(workspace, filename) for filename in os.listdir(workspace) if filename.endswith('.tif')]\n",
    "\n",
    "# Define the criteria names\n",
    "criteria = [\"Land Cover\", \"Slope\"]\n",
    "\n",
    "# Create an empty DataFrame to store the statistics\n",
    "statistics_df = pd.DataFrame(columns=[\"File Name\", \"Criteria and Weight\", \"Mean\", \"Minimum\", \"Maximum\"])\n",
    "\n",
    "# Calculate the number of output files (excluding the first one)\n",
    "num_files = len(output_files) - 1\n",
    "\n",
    "# Analyze each output file (ignoring the first) and append statistics to the DataFrame\n",
    "for i, file_path in enumerate(output_files[1:], start=1):\n",
    "    # Example analysis tasks (you can customize this)\n",
    "    \n",
    "    # Open the raster file\n",
    "    raster = arcpy.Raster(file_path)  # Use arcpy or other libraries for different GIS formats\n",
    "    \n",
    "    # Calculate statistics\n",
    "    mean = arcpy.GetRasterProperties_management(raster, \"MEAN\")\n",
    "    min_value = arcpy.GetRasterProperties_management(raster, \"MINIMUM\")\n",
    "    max_value = arcpy.GetRasterProperties_management(raster, \"MAXIMUM\")\n",
    "    \n",
    "    # Extract the file name from the path\n",
    "    file_name = os.path.basename(file_path)\n",
    "    \n",
    "    # Calculate weights based on linear progression, with 0.5 for the middle value\n",
    "    weight_land_cover = i / num_files if i <= num_files / 2 else 1 - (i - num_files / 2) / num_files\n",
    "    weight_slope = 1 - weight_land_cover\n",
    "    \n",
    "    # Create a single string for Criteria and Weight\n",
    "    criteria_and_weight = f\"{criteria[0]} Weight {weight_land_cover:.1f}, {criteria[1]} Weight {weight_slope:.1f}\"\n",
    "    \n",
    "    # Append statistics to the DataFrame\n",
    "    statistics_df = statistics_df.append({\"File Name\": file_name, \"Criteria and Weight\": criteria_and_weight, \"Mean\": mean, \"Minimum\": min_value, \"Maximum\": max_value}, ignore_index=True)\n",
    "\n",
    "# Save the table to a CSV file\n",
    "output_table = r\"C:\\Users\\jake1\\OneDrive\\Documents\\ArcGIS\\Projects\\Lab2_pt2\\results_table.csv\"\n",
    "statistics_df.to_csv(output_table, index=False)\n",
    "\n",
    "print('Table successfully created')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ArcGISPro",
   "language": "Python",
   "name": "python3"
  },
  "language_info": {
   "file_extension": ".py",
   "name": "python",
   "version": "3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
