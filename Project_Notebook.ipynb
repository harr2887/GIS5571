{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Solar Array Installation Suitability\n",
    "#### GIS 5571: Project Rough Draft\n",
    "#### Author: Jacob Harris\n",
    "---\n",
    "For this project, I'm using National Land Cover Data (NLCD) from 2019, MN County Boundary data, and a Digital Elevation Model to perform site suitability analysis for solar panel array installations in Hennepin County, MN. \n",
    "\n",
    "First, let's set up our ETL by gathering the necessary data and merging it into a single directory."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "All folders successfully downloaded and extracted\n"
     ]
    }
   ],
   "source": [
    "import requests\n",
    "import zipfile\n",
    "import os\n",
    "\n",
    "# Function to download and extract a dataset\n",
    "def download_and_extract(url, target_path, extract_path):\n",
    "    response = requests.get(url)\n",
    "    if response.status_code == 200:\n",
    "        with open(target_path, 'wb') as file:\n",
    "            file.write(response.content)\n",
    "        with zipfile.ZipFile(target_path, 'r') as zip_ref:\n",
    "            zip_ref.extractall(extract_path)\n",
    "\n",
    "# URLs for the datasets\n",
    "NLCD_url = 'https://resources.gisdata.mn.gov/pub/gdrs/data/pub/us_mn_state_dnr/biota_landcover_nlcd_mn_2019/tif_biota_landcover_nlcd_mn_2019.zip'\n",
    "DEM_url = 'https://resources.gisdata.mn.gov/pub/gdrs/data/pub/us_mn_state_dnr/elev_30m_digital_elevation_model/fgdb_elev_30m_digital_elevation_model.zip'\n",
    "county_url = 'https://resources.gisdata.mn.gov/pub/gdrs/data/pub/us_mn_state_dnr/bdry_counties_in_minnesota/shp_bdry_counties_in_minnesota.zip'\n",
    "\n",
    "# Directory where you want to save the datasets\n",
    "base_dir = r\"C:\\Users\\jake1\\OneDrive\\Documents\\ArcGIS\\Projects\\GIS_5571_Project\"\n",
    "# Create new directories for unzipped data\n",
    "unzipped_NLCD_dir = os.path.join(base_dir, 'Unzipped Landcover')\n",
    "unzipped_DEM_dir = os.path.join(base_dir, 'Unzipped Elevation')\n",
    "unzipped_county_dir = os.path.join(base_dir, 'Unzipped Counties')\n",
    "\n",
    "# Download and extract the landcover dataset\n",
    "NLCD_path = os.path.join(base_dir, 'landcover.zip')\n",
    "download_and_extract(NLCD_url, NLCD_path, unzipped_NLCD_dir)\n",
    "\n",
    "# Download and extract the elevation dataset\n",
    "DEM_path = os.path.join(base_dir, 'elevation.zip')\n",
    "download_and_extract(DEM_url, DEM_path, unzipped_DEM_dir)\n",
    "\n",
    "# Download and extract the counties dataset\n",
    "county_path = os.path.join(base_dir, 'counties.zip')\n",
    "download_and_extract(county_url, county_path, unzipped_county_dir)\n",
    "\n",
    "print(\"All folders successfully downloaded and extracted\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data from Unzipped Landcover was merged\n",
      "Data from Unzipped Elevation was merged\n",
      "Data from Unzipped Counties was merged\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import shutil\n",
    "\n",
    "# Define the new folder name\n",
    "merged_fh = 'merged_data'\n",
    "\n",
    "# Create a directory for the merged data\n",
    "merged_folder = os.path.join(base_dir, merged_fh)\n",
    "os.makedirs(merged_folder, exist_ok=True)\n",
    "\n",
    "# List the subdirectories to merge\n",
    "subdirectories = ['Unzipped Landcover', 'Unzipped Elevation', 'Unzipped Counties']\n",
    "\n",
    "# Iterate through the subdirectories and copy their contents to the merged folder\n",
    "for subdirectory in subdirectories:\n",
    "    subdirectory_path = os.path.join(base_dir, subdirectory)\n",
    "    if os.path.exists(subdirectory_path):\n",
    "        for root, dirs, files in os.walk(subdirectory_path):\n",
    "            for file in files:\n",
    "                file_path = os.path.join(root, file)\n",
    "                shutil.copy(file_path, merged_folder)\n",
    "    print(\"Data from\", subdirectory, \"was merged\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### File Setup Complete!\n",
    "\n",
    "Now, our input data are conveniently merged into a single folder called 'merged_data'\n",
    "\n",
    "**Action Required:** Move the 'mn_county_boundaries' shape files from merged_data dir to the parent directory, GIS_5571_Project."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Clipping and selecting Wabasha and Winona counties completed.\n"
     ]
    }
   ],
   "source": [
    "import arcpy\n",
    "\n",
    "# Set the workspace and input feature class\n",
    "arcpy.env.workspace = r\"C:\\Users\\Track\\OneDrive\\Documents\\ArcGIS\\Projects\\GIS_5571_Project\"\n",
    "input_feature_class = \"mn_county_boundaries\"\n",
    "\n",
    "# Select county boundaries\n",
    "selected = arcpy.management.SelectLayerByAttribute(input_feature_class, \"NEW_SELECTION\", where_clause = \"CTY_Name IN ('Hennepin')\")\n",
    "\n",
    "# Create a feature layer with the selection\n",
    "arcpy.management.CopyFeatures(selected, \"Selected_Counties\")\n",
    "\n",
    "# Specify the output feature class for the selected features\n",
    "output_feature_class = r\"C:\\Users\\Track\\OneDrive\\Documents\\ArcGIS\\Projects\\GIS_5571_Project\\mn_county_boundaries_clip\"\n",
    "\n",
    "print(\"Clipping and selecting Wabasha and Winona counties completed.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ArcGIS Pro Map \n",
    "\n",
    "You should now see that two feature layers just appeared in your Contents Pane: 'Selected_Counties' and 'mn_county_boundaries_Layer2'.\n",
    "\n",
    "Remove 'mn_county_boundaries_Layer2' so you can see only the Hennepin County boundaries.\n",
    "\n",
    "Now that we have our boundaries for Hennepin County, we need to use the Extract by Mask function to extract our land cover data to *just* our Hennepin County polygon.\n",
    "\n",
    "**Action Required:** Move the \"NLCD_2019_Land_Cover.tif\" files to the parent directory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Land Cover layer successfully extracted\n"
     ]
    }
   ],
   "source": [
    "# Confine land cover data to selected counties using extract by mask function\n",
    "land_cover = arcpy.sa.ExtractByMask(\n",
    "    in_raster = 'NLCD_2019_Land_Cover.tif',\n",
    "    in_mask_data = 'Selected_Counties',\n",
    "    extraction_area = 'INSIDE',\n",
    "    analysis_extent = 'NLCD_2019_Land_Cover.tif'\n",
    ")\n",
    "print('Land Cover layer successfully extracted')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Map Update\n",
    "\n",
    "If correct, you should see the NLCD 2019 land cover data for Hennepin County in your contents pane as a raster layer named 'land_cover'. To see this on your map, unselect the 'Selected_Counties' layer.\n",
    "\n",
    "Now, we need to add our DEM to the map. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DEM successfully extracted\n"
     ]
    }
   ],
   "source": [
    "# Set the directory of the DEM .gdb to the workspace\n",
    "arcpy.env.workspace = r'C:\\Users\\jake1\\OneDrive\\Documents\\ArcGIS\\Projects\\GIS_5571_Project\\Unzipped Elevation\\elev_30m_digital_elevation_model.gdb'\n",
    "# Name of DEM file: 'digital_elevation_model_30m'\n",
    "\n",
    "# Use extract by mask function to extract the DEM inside Hennepin County \n",
    "DEM = arcpy.sa.ExtractByMask(\n",
    "    in_raster = 'digital_elevation_model_30m',\n",
    "    in_mask_data = 'Selected_Counties',\n",
    "    extraction_area = 'INSIDE',\n",
    "    analysis_extent = 'digital_elevation_model_30m'\n",
    ")\n",
    "\n",
    "print('DEM successfully extracted')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Map Update\n",
    "\n",
    "If correct, you should see the DEM data for Hennepin County in your contents pane as a geodatabase raster named 'DEM'.\n",
    "\n",
    "Now, we need to adjust the slope of our DEM."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Slope successfully adjusted\n"
     ]
    }
   ],
   "source": [
    "# Create string variable for .gdb directory\n",
    "gdb_dir = (base_dir + '\\GIS_5571_Project.gdb')\n",
    "\n",
    "# Set workspace to our .gdb directory\n",
    "arcpy.env.workspace = gdb_dir\n",
    "\n",
    "# Find slope from DEM\n",
    "slope = arcpy.sa.Slope(\n",
    "    in_raster = \"DEM\",\n",
    "    output_measurement = \"DEGREE\",\n",
    "    z_factor = 1,\n",
    "    method = \"PLANAR\",\n",
    "    z_unit = \"METER\")\n",
    "\n",
    "print('Slope successfully extracted')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "value: 13.50292\n",
      "value: 27.00584\n",
      "value: 40.50876\n",
      "value: 54.01168\n",
      "value: 67.51460\n"
     ]
    }
   ],
   "source": [
    "# Math to figure out my slope reclassification values\n",
    "def create_eql_classes(length, max_value):\n",
    "    if length <= 0:\n",
    "        return []  # Return an empty list if the length is non-positive\n",
    "\n",
    "    # Calculate the value to be assigned to each element\n",
    "    value = max_value / length\n",
    "\n",
    "    # Create the list using a list comprehension\n",
    "    result_list = [value * (i + 1) for i in range(length)]\n",
    "    \n",
    "    return result_list\n",
    "\n",
    "# Initialize parameters\n",
    "length = 5\n",
    "max_value = 67.5146\n",
    "# Call function\n",
    "my_list = create_eql_classes(length, max_value)\n",
    "\n",
    "# List output values\n",
    "for i in my_list:\n",
    "    print('value: {:.5f}'.format(i))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Slope reclassified\n"
     ]
    }
   ],
   "source": [
    "# Reclassify DEM slope\n",
    "slope_reclass = arcpy.sa.Reclassify(\n",
    "    in_raster = \"slope\",\n",
    "    reclass_field = \"VALUE\",\n",
    "    remap = \"0 13.50292 5;13.50292 27.00584 4;27.00584 40.50876 3;40.50876 54.01168 2;54.01168 67.5146 1\",\n",
    "    missing_values = \"DATA\"\n",
    ")\n",
    "\n",
    "print('Slope reclassified')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Land cover reclassified\n"
     ]
    }
   ],
   "source": [
    "# Reclassify NLCD data\n",
    "reclass_NLCD = arcpy.sa.Reclassify(\n",
    "    in_raster = \"land_cover\",\n",
    "    reclass_field = \"NLCD_Land\",\n",
    "    remap = \"'Open Water' 1;'Developed, Open Space' 5;'Developed, Low Intensity' 3;'Developed, Medium Intensity' 3;'Developed, High Intensity' 3;'Barren Land' 5;'Deciduous Forest' 1;'Evergreen Forest' 1;'Mixed Forest' 1;Shrub/Scrub 5;Herbaceous 2;Hay/Pasture 4;'Cultivated Crops' 3;'Woody Wetlands' 1;'Emergent Herbaceous Wetlands' 1\",\n",
    "    missing_values = \"DATA\"\n",
    ")\n",
    "\n",
    "print('Land cover reclassified')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sensitivity analysis completed.\n"
     ]
    }
   ],
   "source": [
    "# Set the workspace and environment settings\n",
    "arcpy.env.workspace = gdb_dir\n",
    "arcpy.env.overwriteOutput = True\n",
    "\n",
    "# Define the input data (Land Cover and DEM)\n",
    "land_cover = \"reclass_NLCD\"\n",
    "dem = \"slope_reclass\"\n",
    "\n",
    "# Define the output folder for saving results\n",
    "output_folder = base_dir\n",
    "\n",
    "# Create a list of weight values to iterate through\n",
    "weight_values = [0.1, 0.2, 0.3, 0.4, 0.5, 0.6, 0.7, 0.8, 0.9]\n",
    "\n",
    "# Iterate through different weight values\n",
    "for weight in weight_values:\n",
    "    # Calculate suitability using weighted overlay\n",
    "    weighted_suitability = (arcpy.Raster(land_cover) * weight) + (arcpy.Raster(dem) * (1 - weight))\n",
    "\n",
    "    # Normalize the suitability scores if needed\n",
    "    # normalized_suitability = arcpy.Normalize(weighted_suitability)\n",
    "\n",
    "    # Save the suitability raster with a filename based on the weight\n",
    "    output_name = f\"Suitability_w{int(weight * 100)}.tif\"\n",
    "    output_path = os.path.join(output_folder, output_name)\n",
    "    weighted_suitability.save(output_path)\n",
    "\n",
    "    # Optionally, perform further analysis or reporting here\n",
    "\n",
    "print(\"Sensitivity analysis completed.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Analysis for C:\\Users\\jake1\\OneDrive\\Documents\\ArcGIS\\Projects\\GIS_5571_Project\\NLCD_2019_Land_Cover.tif:\n",
      "Mean: 60.410397229585\n",
      "Minimum: 0\n",
      "Maximum: 95\n",
      "Analysis for C:\\Users\\jake1\\OneDrive\\Documents\\ArcGIS\\Projects\\GIS_5571_Project\\Suitability_w10.tif:\n",
      "Mean: 4.6787405846439\n",
      "Minimum: 1\n",
      "Maximum: 5\n",
      "Analysis for C:\\Users\\jake1\\OneDrive\\Documents\\ArcGIS\\Projects\\GIS_5571_Project\\Suitability_w20.tif:\n",
      "Mean: 4.4764114543555\n",
      "Minimum: 1\n",
      "Maximum: 5\n",
      "Analysis for C:\\Users\\jake1\\OneDrive\\Documents\\ArcGIS\\Projects\\GIS_5571_Project\\Suitability_w30.tif:\n",
      "Mean: 4.2740825401771\n",
      "Minimum: 1\n",
      "Maximum: 5\n",
      "Analysis for C:\\Users\\jake1\\OneDrive\\Documents\\ArcGIS\\Projects\\GIS_5571_Project\\Suitability_w40.tif:\n",
      "Mean: 4.0717534494963\n",
      "Minimum: 1\n",
      "Maximum: 5\n",
      "Analysis for C:\\Users\\jake1\\OneDrive\\Documents\\ArcGIS\\Projects\\GIS_5571_Project\\Suitability_w50.tif:\n",
      "Mean: 3.8694245139983\n",
      "Minimum: 1\n",
      "Maximum: 5\n",
      "Analysis for C:\\Users\\jake1\\OneDrive\\Documents\\ArcGIS\\Projects\\GIS_5571_Project\\Suitability_w60.tif:\n",
      "Mean: 3.6670955946101\n",
      "Minimum: 1\n",
      "Maximum: 5\n",
      "Analysis for C:\\Users\\jake1\\OneDrive\\Documents\\ArcGIS\\Projects\\GIS_5571_Project\\Suitability_w70.tif:\n",
      "Mean: 3.4647664871938\n",
      "Minimum: 1\n",
      "Maximum: 5\n",
      "Analysis for C:\\Users\\jake1\\OneDrive\\Documents\\ArcGIS\\Projects\\GIS_5571_Project\\Suitability_w80.tif:\n",
      "Mean: 3.2624375355748\n",
      "Minimum: 1\n",
      "Maximum: 5\n",
      "Analysis for C:\\Users\\jake1\\OneDrive\\Documents\\ArcGIS\\Projects\\GIS_5571_Project\\Suitability_w90.tif:\n",
      "Mean: 3.0601083987374\n",
      "Minimum: 1\n",
      "Maximum: 5\n"
     ]
    }
   ],
   "source": [
    "# Analysis of Suitability \n",
    "\n",
    "# Set your workspace folder where output files are located\n",
    "arcpy.env.workspace = base_dir\n",
    "workspace = base_dir\n",
    "\n",
    "# List of output raster files\n",
    "output_files = [os.path.join(workspace, filename) for filename in os.listdir(workspace) if filename.endswith('.tif')]\n",
    "\n",
    "# Analyze each output file\n",
    "for file_path in output_files:\n",
    "    # Example analysis tasks (you can customize this)\n",
    "    \n",
    "    # Open the raster file\n",
    "    raster = arcpy.Raster(file_path)  # Use arcpy or other libraries for different GIS formats\n",
    "    \n",
    "    # Calculate statistics\n",
    "    mean = arcpy.GetRasterProperties_management(raster, \"MEAN\")\n",
    "    min_value = arcpy.GetRasterProperties_management(raster, \"MINIMUM\")\n",
    "    max_value = arcpy.GetRasterProperties_management(raster, \"MAXIMUM\")\n",
    "    \n",
    "    # Print or save the results\n",
    "    print(f\"Analysis for {file_path}:\")\n",
    "    print(f\"Mean: {mean}\")\n",
    "    print(f\"Minimum: {min_value}\")\n",
    "    print(f\"Maximum: {max_value}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Table successfully created\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "\n",
    "# List of output raster files\n",
    "output_files = [os.path.join(workspace, filename) for filename in os.listdir(workspace) if filename.endswith('.tif')]\n",
    "\n",
    "# Define the criteria names\n",
    "criteria = [\"Land Cover\", \"Slope\"]\n",
    "\n",
    "# Create an empty DataFrame to store the statistics\n",
    "statistics_df = pd.DataFrame(columns=[\"File Name\", \"Criteria and Weight\", \"Mean\", \"Minimum\", \"Maximum\"])\n",
    "\n",
    "# Calculate the number of output files (excluding the first one)\n",
    "num_files = len(output_files) - 1\n",
    "\n",
    "# Analyze each output file (ignoring the first) and append statistics to the DataFrame\n",
    "for i, file_path in enumerate(output_files[1:], start=1):\n",
    "    # Example analysis tasks (you can customize this)\n",
    "    \n",
    "    # Open the raster file\n",
    "    raster = arcpy.Raster(file_path)  # Use arcpy or other libraries for different GIS formats\n",
    "    \n",
    "    # Calculate statistics\n",
    "    mean = arcpy.GetRasterProperties_management(raster, \"MEAN\")\n",
    "    min_value = arcpy.GetRasterProperties_management(raster, \"MINIMUM\")\n",
    "    max_value = arcpy.GetRasterProperties_management(raster, \"MAXIMUM\")\n",
    "    \n",
    "    # Extract the file name from the path\n",
    "    file_name = os.path.basename(file_path)\n",
    "    \n",
    "    # Calculate weights based on linear progression, with 0.5 for the middle value\n",
    "    weight_land_cover = i / num_files if i <= num_files / 2 else 1 - (i - num_files / 2) / num_files\n",
    "    weight_slope = 1 - weight_land_cover\n",
    "    \n",
    "    # Create a single string for Criteria and Weight\n",
    "    criteria_and_weight = f\"{criteria[0]} Weight {weight_land_cover:.1f}, {criteria[1]} Weight {weight_slope:.1f}\"\n",
    "    \n",
    "    # Append statistics to the DataFrame\n",
    "    statistics_df = statistics_df.append({\"File Name\": file_name, \"Criteria and Weight\": criteria_and_weight, \"Mean\": mean, \"Minimum\": min_value, \"Maximum\": max_value}, ignore_index=True)\n",
    "\n",
    "# Save the table to a CSV file\n",
    "output_table = r\"C:\\Users\\jake1\\OneDrive\\Documents\\ArcGIS\\Projects\\GIS_5571_Project\\results_table2.csv\"\n",
    "statistics_df.to_csv(output_table, index=False)\n",
    "\n",
    "print('Table successfully created')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Further analysis to come..."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ArcGISPro",
   "language": "Python",
   "name": "python3"
  },
  "language_info": {
   "file_extension": ".py",
   "name": "python",
   "version": "3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
