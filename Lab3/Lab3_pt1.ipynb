{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Lab 3 Part 1: Dory Sensitivity Analysis\n",
    "\n",
    "The following notebook shows my work for Part 1 of Lab 3. In this notebook I compute 3 different optimal routes for Dory to travel from her house to the picnic area through a sensitivity anaylsis of weight combinations 0.25, 0.5, and 0.75.\n",
    "\n",
    "**Disclaimer** ChatGPT was used for some parts of this notebook, most notable for the sensitivity analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "All folders successfully downloaded and extracted\n"
     ]
    }
   ],
   "source": [
    "import requests\n",
    "import zipfile\n",
    "import os\n",
    "\n",
    "# Function to download and extract a dataset\n",
    "def download_and_extract(url, target_path, extract_path):\n",
    "    response = requests.get(url)\n",
    "    if response.status_code == 200:\n",
    "        with open(target_path, 'wb') as file:\n",
    "            file.write(response.content)\n",
    "        with zipfile.ZipFile(target_path, 'r') as zip_ref:\n",
    "            zip_ref.extractall(extract_path)\n",
    "\n",
    "# URLs for the datasets\n",
    "NLCD_url = 'https://resources.gisdata.mn.gov/pub/gdrs/data/pub/us_mn_state_dnr/biota_landcover_nlcd_mn_2019/tif_biota_landcover_nlcd_mn_2019.zip'\n",
    "DEM_url = 'https://resources.gisdata.mn.gov/pub/gdrs/data/pub/us_mn_state_dnr/elev_30m_digital_elevation_model/fgdb_elev_30m_digital_elevation_model.zip'\n",
    "county_url = 'https://resources.gisdata.mn.gov/pub/gdrs/data/pub/us_mn_state_dnr/bdry_counties_in_minnesota/shp_bdry_counties_in_minnesota.zip'\n",
    "\n",
    "# Directory where you want to save the datasets\n",
    "base_dir = r\"C:\\Users\\jake1\\OneDrive\\Documents\\ArcGIS\\Projects\\Lab3_pt1\"\n",
    "# Create new directories for unzipped data\n",
    "unzipped_NLCD_dir = os.path.join(base_dir, 'Unzipped Landcover')\n",
    "unzipped_DEM_dir = os.path.join(base_dir, 'Unzipped Elevation')\n",
    "unzipped_county_dir = os.path.join(base_dir, 'Unzipped Counties')\n",
    "\n",
    "# Download and extract the landcover dataset\n",
    "NLCD_path = os.path.join(base_dir, 'landcover.zip')\n",
    "download_and_extract(NLCD_url, NLCD_path, unzipped_NLCD_dir)\n",
    "\n",
    "# Download and extract the elevation dataset\n",
    "DEM_path = os.path.join(base_dir, 'elevation.zip')\n",
    "download_and_extract(DEM_url, DEM_path, unzipped_DEM_dir)\n",
    "\n",
    "# Download and extract the counties dataset\n",
    "county_path = os.path.join(base_dir, 'counties.zip')\n",
    "download_and_extract(county_url, county_path, unzipped_county_dir)\n",
    "\n",
    "print(\"All folders successfully downloaded and extracted\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data from Unzipped Landcover was merged\n",
      "Data from Unzipped Elevation was merged\n",
      "Data from Unzipped Counties was merged\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import shutil\n",
    "\n",
    "# Define the new folder name\n",
    "merged_fh = 'geodatabase'\n",
    "\n",
    "# Create a directory for the merged data\n",
    "merged_folder = os.path.join(base_dir, merged_fh)\n",
    "os.makedirs(merged_folder, exist_ok=True)\n",
    "\n",
    "# List the subdirectories to merge\n",
    "subdirectories = ['Unzipped Landcover', 'Unzipped Elevation', 'Unzipped Counties']\n",
    "\n",
    "# Iterate through the subdirectories and copy their contents to the merged folder\n",
    "for subdirectory in subdirectories:\n",
    "    subdirectory_path = os.path.join(base_dir, subdirectory)\n",
    "    if os.path.exists(subdirectory_path):\n",
    "        for root, dirs, files in os.walk(subdirectory_path):\n",
    "            for file in files:\n",
    "                file_path = os.path.join(root, file)\n",
    "                shutil.copy(file_path, merged_folder)\n",
    "    print(\"Data from\", subdirectory, \"was merged\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### File Setup Complete!\n",
    "\n",
    "Now, our input data are conveniently merged into a single folder called 'merged_data'\n",
    "\n",
    "**Action Required:** Move the 'mn_county_boundaries' shape files from merged_data dir to the parent directory, Lab3_pt1."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Successfully Clipped counties of interest.\n"
     ]
    }
   ],
   "source": [
    "import arcpy\n",
    "# Set the workspace and input feature class\n",
    "arcpy.env.workspace = r\"C:\\Users\\jake1\\OneDrive\\Documents\\ArcGIS\\Projects\\Lab3_pt1\"\n",
    "input_feature_class = \"mn_county_boundaries\"\n",
    "\n",
    "# Select county boundaries\n",
    "selected = arcpy.management.SelectLayerByAttribute(input_feature_class, \"NEW_SELECTION\", where_clause = \"CTY_Name IN ('Wabasha', 'Winona', 'Olmsted')\")\n",
    "\n",
    "# Create a feature layer with the selection\n",
    "arcpy.management.CopyFeatures(selected, \"Selected_Counties\")\n",
    "\n",
    "# Specify the output feature class for the selected features\n",
    "output_feature_class = r\"C:\\Users\\jake1\\OneDrive\\Documents\\ArcGIS\\Projects\\Lab_Part2\\mn_county_boundaries_Clip\"\n",
    "\n",
    "print(\"Successfully Clipped counties of interest.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ArcGIS Pro Map \n",
    "\n",
    "You should now see that two feature layers just appeared in your Contents Pane: 'Selected_Counties' and 'mn_county_boundaries_Layer2'.\n",
    "\n",
    "Remove 'mn_county_boundaries_Layer2' so you can see only the Hennepin County boundaries.\n",
    "\n",
    "Now that we have our boundaries for Hennepin County, we need to use the Extract by Mask function to extract our land cover data to *just* our clipped county polygons.\n",
    "\n",
    "**Action Required:** Move the \"NLCD_2019_Land_Cover.tif\" files to the parent directory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Land Cover layer successfully extracted\n"
     ]
    }
   ],
   "source": [
    "# Confine land cover data to selected counties using extract by mask tool\n",
    "land_cover = arcpy.sa.ExtractByMask(\n",
    "    in_raster=\"NLCD_2019_Land_Cover.tif\",\n",
    "    in_mask_data=\"Selected_Counties\",\n",
    "    extraction_area=\"INSIDE\",\n",
    "    analysis_extent = \"NLCD_2019_Land_Cover.tif\"\n",
    ")\n",
    "print('Land Cover layer successfully extracted')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Map Update\n",
    "\n",
    "If correct, you should see the NLCD 2019 land cover data for Hennepin County in your contents pane as a raster layer named 'land_cover'. To see this on your map, unselect the 'Selected_Counties' layer.\n",
    "\n",
    "Now, we need to add our DEM to the map. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DEM successfully extracted\n"
     ]
    }
   ],
   "source": [
    "# Set the directory of the DEM .gdb to the workspace\n",
    "arcpy.env.workspace = r'C:\\Users\\jake1\\OneDrive\\Documents\\ArcGIS\\Projects\\GIS_5571_Project\\Unzipped Elevation\\elev_30m_digital_elevation_model.gdb'\n",
    "# Name of DEM file: 'digital_elevation_model_30m'\n",
    "\n",
    "# Use extract by mask function to extract the DEM inside Hennepin County \n",
    "DEM = arcpy.sa.ExtractByMask(\n",
    "    in_raster = 'digital_elevation_model_30m',\n",
    "    in_mask_data = 'Selected_Counties',\n",
    "    extraction_area = 'INSIDE',\n",
    "    analysis_extent = 'digital_elevation_model_30m'\n",
    ")\n",
    "\n",
    "print('DEM successfully extracted')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Map Update\n",
    "\n",
    "If correct, you should see the DEM data for Hennepin County in your contents pane as a geodatabase raster named 'DEM'.\n",
    "\n",
    "Now, we need to adjust the slope of our DEM."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Slope successfully adjusted\n"
     ]
    }
   ],
   "source": [
    "gdb_dir = os.path.join(base_dir, 'Lab3_pt1.gdb')\n",
    "\n",
    "arcpy.env.workspace = gdb_dir\n",
    "\n",
    "# Find slope from DEM\n",
    "Slope_Extrac1 = arcpy.sa.Slope(\n",
    "    in_raster=\"Extract_digi1\",\n",
    "    output_measurement=\"DEGREE\",\n",
    "    z_factor=1,\n",
    "    method=\"PLANAR\",\n",
    "    z_unit=\"METER\")\n",
    "\n",
    "print('Slope successfully adjusted')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "value: 15.87664\n",
      "value: 31.75328\n",
      "value: 47.62992\n",
      "value: 63.50656\n",
      "value: 79.38319\n"
     ]
    }
   ],
   "source": [
    "# Math to figure out my slope reclassification values\n",
    "def create_eql_classes(length, max_value):\n",
    "    if length <= 0:\n",
    "        return []  # Return an empty list if the length is non-positive\n",
    "\n",
    "    # Calculate the value to be assigned to each element\n",
    "    value = max_value / length\n",
    "\n",
    "    # Create the list using a list comprehension\n",
    "    result_list = [value * (i + 1) for i in range(length)]\n",
    "    \n",
    "    return result_list\n",
    "\n",
    "# Initialize parameters\n",
    "length = 5\n",
    "max_value = 79.383194\n",
    "# Call function\n",
    "my_list = create_eql_classes(length, max_value)\n",
    "\n",
    "# List output values\n",
    "for i in my_list:\n",
    "    print('value: {:.5f}'.format(i))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Slope reclassified\n"
     ]
    }
   ],
   "source": [
    "# Reclassify DEM slope\n",
    "slope_reclass = arcpy.sa.Reclassify(\n",
    "    in_raster=\"Slope_Extrac1\",\n",
    "    reclass_field=\"VALUE\",\n",
    "    remap=\"0 16 1;16 32 2;32 48 3;48 64 4;64 79.383194 5\",\n",
    "    missing_values=\"DATA\"\n",
    ")\n",
    "print('Slope reclassified')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Land Cover reclassified\n"
     ]
    }
   ],
   "source": [
    "# Reclassify NLCD data\n",
    "reclass_NLCD = arcpy.sa.Reclassify(\n",
    "    in_raster=\"land_cover\",\n",
    "    reclass_field=\"NLCD_Land\",\n",
    "    remap=\"'Open Water' 5;'Developed, Open Space' 1;'Developed, Low Intensity' 1;'Developed, Medium Intensity' 1;'Developed, High Intensity' 5;'Barren Land' 1;'Deciduous Forest' 1;'Evergreen Forest' 1;'Mixed Forest' 1;Shrub/Scrub 1;Herbaceous 1;Hay/Pasture 3;'Cultivated Crops' 5;'Woody Wetlands' 3;'Emergent Herbaceous Wetlands' 2\",\n",
    "    missing_values=\"DATA\"\n",
    ")\n",
    "print('Land Cover reclassified')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "base_dir = r\"C:\\Users\\jake1\\OneDrive\\Documents\\ArcGIS\\Projects\\Lab3_pt1\"\n",
    "gdb_dir = os.path.join(base_dir, 'Lab3_pt1.gdb')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'html_attributions': [], 'results': [{'business_status': 'OPERATIONAL', 'formatted_address': '19206 MN-74, St Charles, MN 55972, United States', 'geometry': {'location': {'lat': 44.0543872, 'lng': -92.0448256}, 'viewport': {'northeast': {'lat': 44.05581302989273, 'lng': -92.04338092010728}, 'southwest': {'lat': 44.05311337010728, 'lng': -92.04608057989272}}}, 'icon': 'https://maps.gstatic.com/mapfiles/place_api/icons/v1/png_71/park-71.png', 'icon_background_color': '#4DB546', 'icon_mask_base_uri': 'https://maps.gstatic.com/mapfiles/place_api/icons/v2/tree_pinlet', 'name': 'North Picnic area', 'opening_hours': {}, 'photos': [{'height': 3024, 'html_attributions': ['<a href=\"https://maps.google.com/maps/contrib/112937281817958526101\">Casen Raehtz</a>'], 'photo_reference': 'AWU5eFjrE-BzS0b-C9uEBXGeyjdBoAvNUcDVau8ZKfyuEPK2Ol-l2O4NF6ONL47_1JnYv1ZujScqCIiPoIQL15IhcIP6U-RUZ-6hHDsAhtDO18uk-C9EpgEINlasEUHNxtIQEl8GtirL0uK3kAaQi9gTfi8n4Vzw9QayZWhXLGKEIsoJzufF', 'width': 4032}], 'place_id': 'ChIJTeSfRg-X-YcRZM-pODlD2_U', 'plus_code': {'compound_code': '3X34+Q3 St Charles, Minnesota', 'global_code': '86P93X34+Q3'}, 'rating': 4.6, 'reference': 'ChIJTeSfRg-X-YcRZM-pODlD2_U', 'types': ['park', 'point_of_interest', 'establishment'], 'user_ratings_total': 7}], 'status': 'OK'}\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "import requests\n",
    "\n",
    "north_picnic = requests.get('https://maps.googleapis.com/maps/api/place/textsearch/json?query=Whitewater%20State%20Park%20North%20Picnic%20Area&inputtype=textquery&fields=fomatted_address%2Cgeometry&key=AIzaSyBIyIWXZTKTZXyZLLj_YXHFg4nkYjdj4pg')\n",
    "Npicnic_json = north_picnic.json()\n",
    "print(Npicnic_json)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div class='gpresult'><h2>Messages</h2><div id='messages' data-messages='[\"Start Time: Sunday, December 10, 2023 1:09:09 PM\",\"Succeeded at Sunday, December 10, 2023 1:09:09 PM (Elapsed Time: 0.28 seconds)\"]' data-show='true'><div id = 'default' /></div></div>"
      ],
      "text/plain": [
       "<Result 'C:\\\\Users\\\\jake1\\\\OneDrive\\\\Documents\\\\ArcGIS\\\\Projects\\\\Lab3_pt1\\\\Lab3_pt1.gdb\\\\start_pt'>"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lat = Npicnic_json['results'][0]['geometry']['location']['lat']\n",
    "lng = Npicnic_json['results'][0]['geometry']['location']['lng']\n",
    "\n",
    "picnic_area = arcpy.PointGeometry(\n",
    "    arcpy.Point(lng,lat),\n",
    "    spatial_reference = arcpy.SpatialReference(32615)\n",
    ")\n",
    "\n",
    "arcpy.management.CopyFeatures(\n",
    "    picnic_area,\n",
    "    'end_pt'\n",
    ")\n",
    "\n",
    "# Create the point for Dora's house\n",
    "\n",
    "dora_house = arcpy.PointGeometry(\n",
    "    arcpy.Point(-92.148796, 44.127985),\n",
    "    spatial_reference = arcpy.SpatialReference(32615)\n",
    ")\n",
    "\n",
    "arcpy.management.CopyFeatures(\n",
    "    dora_house,\n",
    "    'start_pt'\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Sensitivity Analysis\n",
    "\n",
    "#### **Disclaimer**: The sensitivity analysis was generated in part by ChatGPT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reclass_Slop1_w25_Reclass_Extr1_w75 successfully saved\n",
      "LC_Slope_w50 successfully saved\n",
      "Reclass_Extr1_w25_Reclass_Slop1_w75 successfully saved\n",
      "LC_Slope_w50 successfully saved\n"
     ]
    }
   ],
   "source": [
    "\n",
    "#changes weights\n",
    "import arcpy\n",
    "import os\n",
    "\n",
    "path_dir = os.path.join(base_dir, 'paths')\n",
    "\n",
    "# Set the workspace where your rasters are located\n",
    "arcpy.env.workspace = gdb_dir\n",
    "output_folder = gdb_dir\n",
    "# List of input raster names\n",
    "input_raster_names = [\"Reclass_Slop1\", \"Reclass_Extr1\"]\n",
    "\n",
    "# Define weight scenarios\n",
    "weight_scenarios = [0.25, 0.5]\n",
    "\n",
    "# Nested loop to process each combination (Source: ChatGPT)\n",
    "for raster1_name in input_raster_names:\n",
    "    for raster2_name in input_raster_names:\n",
    "        for weight in weight_scenarios:\n",
    "            if weight == 0.5:\n",
    "                output_name = f\"LC_Slope_w50\"\n",
    "            else:\n",
    "                output_name = f\"{raster1_name}_w{int(weight * 100)}_{raster2_name}_w{int((1 - weight) * 100)}\"\n",
    "            #Skip if loop wants to pair the same rasters together\n",
    "            if raster1_name == raster2_name:\n",
    "                continue\n",
    "\n",
    "            # Paths to Rasters\n",
    "            raster1 = os.path.join(arcpy.env.workspace, raster1_name)\n",
    "            raster2 = os.path.join(arcpy.env.workspace, raster2_name)\n",
    "\n",
    "            # Create raster combinations\n",
    "            raster1_weighted = arcpy.Raster(raster1) * weight\n",
    "            raster2_weighted = arcpy.Raster(raster2) * (1 - weight)\n",
    "            output_raster = raster1_weighted + raster2_weighted\n",
    "\n",
    "            # Save the output raster\n",
    "            output_raster.save(os.path.join(output_folder, output_name))\n",
    "            print(output_name, 'successfully saved')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Optimal Routing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import arcpy\n",
    "import os\n",
    "base_dir = r\"C:\\Users\\jake1\\OneDrive\\Documents\\ArcGIS\\Projects\\Lab3_pt1\"\n",
    "gdb_dir = os.path.join(base_dir, 'Lab3_pt1.gdb')\n",
    "arcpy.env.workspace = gdb_dir"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# LC weight 50 slope weight 50 route\n",
    "arcpy.intelligence.LeastCostPath(\n",
    "    in_cost_surface = \"LC_Slope_w50\",\n",
    "    in_start_point = \"start_pt\",\n",
    "    in_end_point = \"end_pt\",\n",
    "    out_path_feature_class = os.path.join(gdb_dir, 'LC_Slope_w50_route'),\n",
    "    handle_zeros = \"NO_DATA\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# LC weight 75 slope weight 25 route\n",
    "arcpy.intelligence.LeastCostPath(\n",
    "    in_cost_surface = \"Reclass_Slop1_w25_Reclass_Extr1_w75\",\n",
    "    in_start_point = 'start_pt',\n",
    "    in_end_point = 'end_pt',\n",
    "    out_path_feature_class = os.path.join(gdb_dir, 'Reclass_Slop1_w25_Reclass_Extr1_w75_route'),\n",
    "    handle_zeros = \"NO_DATA\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# LC weight 25 slope weight 75 route\n",
    "arcpy.intelligence.LeastCostPath(\n",
    "    in_cost_surface = \"Reclass_Extr1_w25_Slop1_w75\",\n",
    "    in_start_point = 'start_pt',\n",
    "    in_end_point = 'end_pt',\n",
    "    out_path_feature_class = os.path.join(gdb_dir, 'Reclass_Extr1_w25_Slop1_w75_route'),\n",
    "    handle_zeros = \"NO_DATA\"\n",
    ")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ArcGISPro",
   "language": "Python",
   "name": "python3"
  },
  "language_info": {
   "file_extension": ".py",
   "name": "python",
   "version": "3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
